{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\tests\\\\trainsmall\\\\0.jpg', -1.4156862745098038, -0.3254901960784313, -0.4666666666666667, -0.6235294117647059] <class 'str'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "import imlib as im\n",
    "import numpy as np\n",
    "import pylib as py\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tf2lib as tl\n",
    "import tf2gan as gan\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import data\n",
    "import random\n",
    "import module\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# =                                   param                                    =\n",
    "# ==============================================================================\n",
    "\n",
    "'''py.arg('--dataset', default='summer2winter_yosemite')\n",
    "py.arg('--datasets_dir', default='dataset')\n",
    "py.arg('--load_size', type=int, default=256)  # load image to this size\n",
    "py.arg('--crop_size', type=int, default=256)  # then crop to this size\n",
    "py.arg('--batch_size', type=int, default=1)\n",
    "py.arg('--epochs', type=int, default=200)\n",
    "py.arg('--epoch_decay', type=int, default=100)  # epoch to start decaying learning rate\n",
    "py.arg('--lr', type=float, default=0.0002)\n",
    "py.arg('--beta_1', type=float, default=0.5)\n",
    "py.arg('--adversarial_loss_mode', default='lsgan', choices=['gan', 'hinge_v1', 'hinge_v2', 'lsgan', 'wgan'])\n",
    "py.arg('--gradient_penalty_mode', default='none', choices=['none', 'dragan', 'wgan-gp'])\n",
    "py.arg('--gradient_penalty_weight', type=float, default=10.0)\n",
    "py.arg('--cycle_loss_weight', type=float, default=10.0)\n",
    "py.arg('--identity_loss_weight', type=float, default=0.0)\n",
    "py.arg('--pool_size', type=int, default=50)  # pool size to store fake samples\n",
    "args = py.args()'''\n",
    "adataset='hair'\n",
    "aload_size=256\n",
    "acrop_size=128\n",
    "abatch_size=6\n",
    "apool_size=50\n",
    "aadversarial_loss_mode='lsgan'\n",
    "aepochs=200\n",
    "agradient_penalty_weight=10.0\n",
    "alr=0.0002\n",
    "aepoch_decay=100\n",
    "abeta_1=0.5\n",
    "acycle_loss_weight=10.0\n",
    "aidentity_loss_weight=0.1\n",
    "agradient_penalty_mode='none'\n",
    "\n",
    "# output_dir\n",
    "output_dir = py.join('output', adataset)\n",
    "py.mkdir(output_dir)\n",
    "\n",
    "# save settings\n",
    "#py.args_to_yaml(py.join(output_dir, 'settings.yml'), args)\n",
    "def pointer(path):\n",
    "    s=path.split('\\\\')[-1]\n",
    "    path='data\\\\tests\\\\0.1_color\\\\'+s\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, 3)\n",
    "    img=img.numpy()\n",
    "    img = img / 255.0\n",
    "    img=img*2-1\n",
    "    lis=[img[0,0,0]+img[0,0,1]+img[0,0,2],img[0,0,0],img[0,0,1],img[0,0,2]]\n",
    "    \n",
    "    return lis\n",
    "def parse_fn(path, color):\n",
    "    \n",
    "        ultimate.append(path)\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, 3)  # fix channels to 3\n",
    "        img = tf.image.resize(img, [128, 128])\n",
    "        img2 = tf.io.read_file(color)\n",
    "        img2 = tf.image.decode_png(img2, 3)\n",
    "        img2 = tf.image.resize(img2, [128, 128])\n",
    "        img3 = tf.concat([img, img2], axis=2)\n",
    "        img3=tf.cast(img3,tf.float32)\n",
    "        img3 = tf.clip_by_value(img3, 0, 255) / 255.0\n",
    "        img3=img3*2-1\n",
    "\n",
    "        '''s=path.decode(\"utf-8\").split('\\\\')[-1]\n",
    "        img2 = tf.io.read_file('data\\\\test\\\\0.1_color\\\\'+s)\n",
    "        img2 = tf.image.decode_png(img2, 3)\n",
    "        img3=tf.concat([img,img2],axis=2)'''\n",
    "        return (img3,) \n",
    "def show2(t):\n",
    "    t = tf.squeeze(t)\n",
    "    image=t.numpy()\n",
    "    image=(image+1)/2\n",
    "    image=image*255.0\n",
    "    image=image.astype('uint8')\n",
    "    image2 = Image.fromarray(image, mode='RGB')\n",
    "    image2.show()\n",
    "def imgchck(a):\n",
    "    ten,=a\n",
    "    ten1=ten[0,:,:,:3]\n",
    "    ten2=ten[1,:,:,:3]\n",
    "    show2(ten1)\n",
    "    show2(ten2)\n",
    "    \n",
    "\n",
    "def createdata(l):\n",
    "    n=len(l)\n",
    "    lis=[]\n",
    "    for k in range(n):\n",
    "        s=l[k].split('\\\\')[-1]\n",
    "        s2='data\\\\tests\\\\0.1_color\\\\'+s\n",
    "        lis.append(s2)\n",
    "    return lis\n",
    "def write(txt,B2_imgs,ind=None):\n",
    "    if(ind==None):\n",
    "        with open(txt+'.txt', 'w') as filehandle:\n",
    "            filehandle.writelines(\"%s\\n\" % place for place in B2_imgs)\n",
    "    else:\n",
    "        with open(txt+'.txt', 'w') as filehandle:\n",
    "            filehandle.writelines(\"%s\\n\" % place[ind] for place in B2_imgs)\n",
    "\n",
    "def read(txt):\n",
    "    bcolr=[]\n",
    "    with open(txt+'.txt', 'r') as filehandle:\n",
    "        filecontents = filehandle.readlines()\n",
    "\n",
    "    for line in filecontents:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        current_place = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        bcolr.append(current_place)\n",
    "    return bcolr\n",
    "    \n",
    "# ==============================================================================\n",
    "# =                                    data                                    =\n",
    "# ==============================================================================\n",
    "colordataset=[]\n",
    "\n",
    "B_imgs = py.glob(py.join('data\\\\tests', 'trainsmall'), '*.jpg')\n",
    "B2_imgs=[]\n",
    "for a in B_imgs:\n",
    "    b=pointer(a)\n",
    "    b=list(map(float, b))\n",
    "    b.insert(0,a)\n",
    "    B2_imgs.append(b)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\tests\\\\trainsmall\\\\0.jpg', -1.4156862745098038, -0.3254901960784313, -0.4666666666666667, -0.6235294117647059]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data2=sorted(B2_imgs,key=lambda x:x[2])\n",
    "#write('Red\\\\imgs',data2,ind=0)\n",
    "data3=sorted(B2_imgs,key=lambda x:x[3])\n",
    "#write('Green\\\\imgs',data3,ind=0)\n",
    "data4=sorted(B2_imgs,key=lambda x:x[4])\n",
    "#write('Blue\\\\imgs',data4,ind=0)\n",
    "data1=sorted(B2_imgs,key=lambda x:x[1])\n",
    "#write('imgs',data1,ind=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=[x[0] for x in data1]\n",
    "data2=[x[0] for x in data2]\n",
    "data3=[x[0] for x in data3]\n",
    "data4=[x[0] for x in data4]\n",
    "dr1=sorted(B2_imgs,key=lambda x:x[1],reverse=True)\n",
    "dr1=[x[0] for x in dr1]\n",
    "dr2=sorted(B2_imgs,key=lambda x:x[2],reverse=True)\n",
    "dr2=[x[0] for x in dr2]\n",
    "dr3=sorted(B2_imgs,key=lambda x:x[3],reverse=True)\n",
    "dr3=[x[0] for x in dr3]\n",
    "dr4=sorted(B2_imgs,key=lambda x:x[4],reverse=True)\n",
    "dr4=[x[0] for x in dr4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4896\n",
      "data\\tests\\trainsmall\\91.jpg\n"
     ]
    }
   ],
   "source": [
    "length=len(dr1)\n",
    "print(length)\n",
    "def visualize(data1,dr1,ind):\n",
    "    print(data1[ind])\n",
    "    img = tf.io.read_file(data1[ind])\n",
    "    t1 = tf.image.decode_png(img, 3)\n",
    "    t1=tf.expand_dims(t1,axis=0)\n",
    "    t1=t1.numpy()\n",
    "    t1 = t1 / 255.0\n",
    "    t1=t1*2-1\n",
    "    s=dr1[ind].split('\\\\')[-1]\n",
    "    path='data\\\\tests\\\\0.1_color\\\\'+s\n",
    "    img = tf.io.read_file(path)\n",
    "    t2 = tf.image.decode_png(img, 3)\n",
    "    t2=tf.expand_dims(t2,axis=0)\n",
    "    t2=t2.numpy()\n",
    "    t2 = t2 / 255.0\n",
    "    t2=t2*2-1\n",
    "    img = im.immerge(np.concatenate([t1,t2], axis=0), n_rows=2)\n",
    "    im.imwrite(img, py.join('output\\\\', 'seeing.jpg' ))\n",
    "    image=Image.open('output\\\\seeing.jpg')\n",
    "    image.show()\n",
    "visualize(data1,dr1,4000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\tests\\trainsmall\\195.jpg\n"
     ]
    }
   ],
   "source": [
    "dhyp1=data1[:1000]+data2[:1000]+data3[:1000]+data4[:1000]+data1[4000:]+data2[4000:]+data3[4000:]+data4[4000:]\n",
    "dhyp2=dr1[:1000]+dr2[:1000]+dr3[:1000]+dr4[:1000]+dr1[4000:]+dr2[4000:]+dr3[4000:]+dr4[4000:]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsen(path, color,p2,c2):\n",
    "    \n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, 3)  # fix channels to 3\n",
    "        img = tf.image.resize(img, [128, 128])\n",
    "        img2 = tf.io.read_file(color)\n",
    "        img2 = tf.image.decode_png(img2, 3)\n",
    "        img2 = tf.image.resize(img2, [128, 128])\n",
    "        img3 = tf.concat([img, img2], axis=2)\n",
    "        img3=tf.cast(img3,tf.float32)\n",
    "        img3 = tf.clip_by_value(img3, 0, 255) / 255.0\n",
    "        img3=img3*2-1\n",
    "        \n",
    "        img4 = tf.io.read_file(p2)\n",
    "        img4 = tf.image.decode_png(img4, 3)  # fix channels to 3\n",
    "        img4 = tf.image.resize(img4, [128, 128])\n",
    "        img5 = tf.io.read_file(c2)\n",
    "        img5 = tf.image.decode_png(img5, 3)\n",
    "        img5 = tf.image.resize(img5, [128, 128])\n",
    "        img6 = tf.concat([img4, img5], axis=2)\n",
    "        img6=tf.cast(img6,tf.float32)\n",
    "        img6 = tf.clip_by_value(img6, 0, 255) / 255.0\n",
    "        img6=img6*2-1\n",
    "\n",
    "        '''s=path.decode(\"utf-8\").split('\\\\')[-1]\n",
    "        img2 = tf.io.read_file('data\\\\test\\\\0.1_color\\\\'+s)\n",
    "        img2 = tf.image.decode_png(img2, 3)\n",
    "        img3=tf.concat([img,img2],axis=2)'''\n",
    "        return (img3,img6) \n",
    "    \n",
    "    \n",
    "d1c=createdata(dhyp1)\n",
    "d2c=createdata(dhyp2)\n",
    "len_dataset=len(d1c)//abatch_size\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((dhyp1,d1c,dhyp2,d2c))\n",
    "dataset = dataset.shuffle(2048)\n",
    "dataset = dataset.map(parsen, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.batch(abatch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session starts \n",
      "\n",
      "B 1264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A2B_pool = data.ItemPool(apool_size)\n",
    "#B2A_pool = data.ItemPool(a.pool_size)\n",
    "print('B',len_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# =                                   models                                   =\n",
    "# ==============================================================================\n",
    "\n",
    "G = module.ResnetGenerator(input_shape=(acrop_size, acrop_size, 6))\n",
    "\n",
    "D= module.ConvDiscriminator(input_shape=(acrop_size, acrop_size, 6))\n",
    "#print('generator')\n",
    "#print(G.summary())\n",
    "\n",
    "#print('discriminator')\n",
    "#print(D.summary())\n",
    "\n",
    "\n",
    "\n",
    "d_loss_fn, g_loss_fn = gan.get_adversarial_losses_fn(aadversarial_loss_mode)\n",
    "cycle_loss_fn = tf.losses.MeanAbsoluteError()\n",
    "identity_loss_fn = tf.losses.MeanAbsoluteError()\n",
    "\n",
    "G_lr_scheduler = module.LinearDecay(alr, aepochs * len_dataset, aepoch_decay * len_dataset)\n",
    "D_lr_scheduler = module.LinearDecay(alr, aepochs * len_dataset, aepoch_decay * len_dataset)\n",
    "G_optimizer = keras.optimizers.Adam(learning_rate=G_lr_scheduler, beta_1=abeta_1)\n",
    "D_optimizer = keras.optimizers.Adam(learning_rate=D_lr_scheduler, beta_1=abeta_1)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# =                                 train step                                 =\n",
    "# ==============================================================================\n",
    "\n",
    "@tf.function\n",
    "def train_G(A,B):\n",
    "    with tf.GradientTape() as t:\n",
    "\n",
    "        At=A[:,:,:,3:]\n",
    "        Bt=B[:,:,:,3:]\n",
    "        Ai=A[:,:,:,:3]\n",
    "        Bi=B[:,:,:,:3]\n",
    "\n",
    "        A=tf.concat([Ai,Bt],axis=3)\n",
    "\n",
    "        A2B = G(A, training=True)\n",
    "        A2B=tf.concat([A2B,At],axis=3)\n",
    "        A2B2A = G(A2B, training=True)\n",
    "        B2B = G(B, training=True)\n",
    "\n",
    "        A2B=tf.concat([A2B[:,:,:,:3],Bt],axis=3)\n",
    "        A2B_d_logits = D(A2B, training=True)\n",
    "\n",
    "        A2B_g_loss = g_loss_fn(A2B_d_logits)\n",
    "        A2B2A_cycle_loss = cycle_loss_fn(Ai, A2B2A)\n",
    "        B2B_id_loss = identity_loss_fn(Bi, B2B)\n",
    "\n",
    "        G_loss = A2B_g_loss  + A2B2A_cycle_loss  * acycle_loss_weight   + B2B_id_loss * aidentity_loss_weight\n",
    "\n",
    "    G_grad = t.gradient(G_loss, G.trainable_variables )\n",
    "    G_optimizer.apply_gradients(zip(G_grad, G.trainable_variables ))\n",
    "\n",
    "    return A2B, {'A2B_g_loss': A2B_g_loss,\n",
    "                      'A2B2A_cycle_loss': A2B2A_cycle_loss,\n",
    "                      'B2B_id_loss': B2B_id_loss}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_D(B, A2B):\n",
    "    with tf.GradientTape() as t:\n",
    "        B_d_logits = D(B, training=True)\n",
    "        A2B_d_logits = D(A2B, training=True)\n",
    "\n",
    "        B_d_loss, A2B_d_loss = d_loss_fn(B_d_logits, A2B_d_logits)\n",
    "        #D_gp = gan.gradient_penalty(functools.partial(D, training=True), B, A2B, mode=agradient_penalty_mode)\n",
    "\n",
    "        D_loss = B_d_loss + A2B_d_loss #+ D_gp * agradient_penalty_weight\n",
    "\n",
    "    D_grad = t.gradient(D_loss, D.trainable_variables)\n",
    "    D_optimizer.apply_gradients(zip(D_grad, D.trainable_variables ))\n",
    "\n",
    "    return {'B_d_loss': B_d_loss + A2B_d_loss}\n",
    "\n",
    "\n",
    "def train_step(A, B):\n",
    "    A2B, G_loss_dict = train_G(A, B)\n",
    "\n",
    "    # cannot autograph `A2B_pool`\n",
    "    A2B = A2B_pool(A2B)  # or A2B = A2B_pool(A2B.numpy()), but it is much slower\n",
    "\n",
    "    D_loss_dict = train_D( B, A2B)\n",
    "\n",
    "    return G_loss_dict, D_loss_dict\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample(A,B):\n",
    "    At = A[0, :, :, 3:]\n",
    "    At=tf.expand_dims(At, 0)\n",
    "    Bt = B[0, :, :, 3:]\n",
    "    Bt=tf.expand_dims(Bt, 0)\n",
    "    Ai = A[0, :, :, :3]\n",
    "    Ai=tf.expand_dims(Ai, 0)\n",
    "\n",
    "    A = tf.concat([Ai, Bt], axis=3)\n",
    "\n",
    "    A2B = G(A, training=False)\n",
    "    A2B = tf.concat([A2B, At], axis=3)\n",
    "    A2B2A = G(A2B, training=False)\n",
    "\n",
    "\n",
    "    return Ai,Bt,A2B[:,:,:,:3], A2B2A\n",
    "\n",
    "def show(t,strin):\n",
    "    t = tf.squeeze(t)\n",
    "    image=t.numpy()\n",
    "    image=(image+1)/2\n",
    "    image=image*255.0\n",
    "    image=image.astype('uint8')\n",
    "    image2 = Image.fromarray(image, mode='RGB')\n",
    "    image2.save('output\\\\hair\\\\msample\\\\'+strin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Epoch Loop: 100%|██████████| 1264/1264 [17:19<00:00,  1.22it/s]\n",
      "Inner Epoch Loop: 100%|██████████| 1264/1264 [21:03<00:00,  1.00it/s]\n",
      "Inner Epoch Loop: 100%|██████████| 1264/1264 [23:10<00:00,  1.10s/it]\n",
      "Inner Epoch Loop: 100%|██████████| 1264/1264 [25:24<00:00,  1.21s/it]\n",
      "Inner Epoch Loop: 100%|██████████| 1264/1264 [25:15<00:00,  1.20s/it]\n",
      "Epoch Loop: 100%|██████████| 5/5 [1:52:13<00:00, 1346.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# =                                    run                                     =\n",
    "# ==============================================================================\n",
    "aepochs=5\n",
    "\n",
    "# epoch counter\n",
    "ep_cnt = tf.Variable(initial_value=0, trainable=False, dtype=tf.int64)\n",
    "\n",
    "# checkpoint\n",
    "'''checkpoint = tl.Checkpoint(dict(G=G,\n",
    "                                D=D,\n",
    "                                G_optimizer=G_optimizer,\n",
    "                                D_optimizer=D_optimizer,\n",
    "                                ep_cnt=ep_cnt),\n",
    "                           py.join(output_dir, 'checkpoints'),\n",
    "                           max_to_keep=5)\n",
    "try:  # restore checkpoint including the epoch counter\n",
    "    checkpoint.restore().assert_existing_objects_matched()\n",
    "except Exception as e:\n",
    "    print(e)'''\n",
    "# summary\n",
    "#G=tf.keras.models.load_model('Models\\\\Generator.h5')\n",
    "#D=tf.keras.models.load_model('Models\\\\Discriminator.h5')\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(py.join(output_dir, 'summaries', 'train'))\n",
    "\n",
    "# sample\n",
    "#B_set,a=B\n",
    "#test_iter = iter(B_set)\n",
    "sample_dir = py.join(output_dir, 'samples_training')\n",
    "py.mkdir(sample_dir)\n",
    "\n",
    "\n",
    "# main loop\n",
    "with train_summary_writer.as_default():\n",
    "    for ep in tqdm.trange(aepochs, desc='Epoch Loop'):\n",
    "        if ep < ep_cnt:\n",
    "            continue\n",
    "        count=0\n",
    "\n",
    "        # update epoch counter\n",
    "        ep_cnt.assign_add(1)\n",
    "\n",
    "        # train for an epoch\n",
    "        for x in tqdm.tqdm(dataset, desc='Inner Epoch Loop', total=len_dataset, position=0, leave=True):\n",
    "            A,B=x\n",
    "        #for A in A_set:\n",
    "            G_loss_dict, D_loss_dict = train_step(A, B)\n",
    "\n",
    "            # # summary\n",
    "            tl.summary(G_loss_dict, step=G_optimizer.iterations, name='G_losses')\n",
    "            tl.summary(D_loss_dict, step=G_optimizer.iterations, name='D_losses')\n",
    "            tl.summary({'learning rate': G_lr_scheduler.current_learning_rate}, step=G_optimizer.iterations, name='learning rate')\n",
    "            \n",
    "            if G_optimizer.iterations.numpy() % 100 == 0: \n",
    "                G.save('Models\\\\Generator.h5')\n",
    "                D.save('Models\\\\Discriminator.h5')\n",
    "                \n",
    "            # sample\n",
    "            if G_optimizer.iterations.numpy() % 50 == 0: \n",
    "                '''A = next(test_iter)\n",
    "                m,=A\n",
    "                A=m'''\n",
    "                A,B,A2B, A2B2A = sample(A, B)\n",
    "                show(A2B,'iter_{}_{}.jpg'.format(ep,G_optimizer.iterations.numpy()))\n",
    "                img = im.immerge(np.concatenate([A, A2B, A2B2A, B], axis=0), n_rows=2)\n",
    "                im.imwrite(img, py.join(sample_dir, 'iter-%09d.jpg' % G_optimizer.iterations.numpy()))\n",
    "\n",
    "        # save checkpoint\n",
    "        #checkpoint.save(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "over n out\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "model = tf.keras.models.load_model('modelsbase\\\\12811\\\\Generator.h5')\n",
    "\n",
    "# Create a new model instance\n",
    "def inp(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, 3)  # fix channels to 3\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    img=tf.expand_dims(img, axis=0)\n",
    "    s=path.split('\\\\')[-1]\n",
    "    path2='data\\\\tests\\\\0.1_color\\\\'+s\n",
    "    img2 = tf.io.read_file(path2)\n",
    "    img2 = tf.image.decode_png(img2, 3)  # fix channels to 3\n",
    "    img2 = tf.image.resize(img2, [128, 128])\n",
    "    img2=tf.expand_dims(img2, axis=0)\n",
    "    img3=tf.concat([img,img2],axis=3)\n",
    "    img3=tf.cast(img3,tf.float32)\n",
    "    img3 = tf.clip_by_value(img3, 0, 255) / 255.0\n",
    "    img3=img3*2-1\n",
    "    return img3\n",
    "def sample2(A,B):\n",
    "    At = A[0, :, :, 3:]\n",
    "    At=tf.expand_dims(At, 0)\n",
    "    Bt = B[0, :, :, 3:]\n",
    "    Bt=tf.expand_dims(Bt, 0)\n",
    "    Ai = A[0, :, :, :3]\n",
    "    Ai=tf.expand_dims(Ai, 0)\n",
    "\n",
    "    A = tf.concat([Ai, Bt], axis=3)\n",
    "    #print('never before\\n',A)\n",
    "    \n",
    "    A2B = model(A, training=False)\n",
    "    #print('ever after\\n',A2B)\n",
    "    A2B = tf.concat([A2B, At], axis=3)\n",
    "    A2B2A = model.predict(A2B)\n",
    "\n",
    "\n",
    "    return Ai,Bt,A2B[:,:,:,:3], A2B2A\n",
    "\n",
    "# Check its architecture\n",
    "devset = py.glob(py.join('data\\\\tests', 'dev'), '*.jpg')\n",
    "color=devset.copy()\n",
    "random.shuffle(color)\n",
    "\n",
    "for i in range(100):\n",
    "    A1=inp(devset[i])\n",
    "    B1=inp(color[i])\n",
    "    A1,B1,A2B1, A2B2A1 = sample2(A1, B1)\n",
    "\n",
    "    #show(A2B1,'test_{}.jpg'.format(c))\n",
    "    img = im.immerge(np.concatenate([A1, A2B1, A2B2A1, B1], axis=0), n_rows=2)\n",
    "    im.imwrite(img, py.join('output\\\\test_11\\\\', 'test_{}.jpg'.format(i)))\n",
    "print('over n out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
